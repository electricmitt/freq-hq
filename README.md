# FREQ. - Interactive Mood-Based Music & Visual Experience

An immersive web application that combines AI-generated music with dynamic 3D particle visualizations, creating a unique experience based on your mood.

## Features

- ðŸŽµ AI-powered music generation using Riffusion
- ðŸŒˆ Dynamic 3D particle system with mood-based color schemes
- ðŸŽ¨ Interactive mood selection (Sad, Calm, Anxious)
- ðŸ”Š Smooth audio transitions with fade effects
- ðŸŽ® Responsive controls and intuitive user interface

## Tech Stack

- **Frontend Framework**: Next.js 14 with TypeScript
- **3D Graphics**: Three.js with React Three Fiber
- **State Management**: Zustand
- **Styling**: CSS Modules
- **Audio Processing**: Web Audio API
- **AI Integration**: Riffusion API

## Prerequisites

- Node.js 18.x or later
- npm 9.x or later
- A Riffusion API token (get one at [replicate.com](https://replicate.com))

## Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/freq-hq.git
   cd freq-hq
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Create a `.env.local` file in the root directory and add your Riffusion API token:
   ```
   RIFFUSION_API_TOKEN=your_api_token_here
   ```

4. Start the development server:
   ```bash
   npm run dev
   ```

5. Open [http://localhost:3000](http://localhost:3000) in your browser.

## Project Structure

```
freq-hq/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ParticleSystem/
â”‚   â”‚       â””â”€â”€ ParticleSystem.tsx    # 3D particle visualization
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ generate-music.ts     # Music generation endpoint
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ prediction/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [id].ts           # Prediction status endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ _app.tsx                  # App wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ _document.tsx             # Custom document
â”‚   â”‚   â”‚   â””â”€â”€ experience.tsx            # Main experience page
â”‚   â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â”‚   â””â”€â”€ moodStore.ts              # Zustand store for mood state
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â”œâ”€â”€ Experience.module.css     # Experience page styles
â”‚   â”‚       â””â”€â”€ globals.css               # Global styles
â”‚   â”œâ”€â”€ .env.local                        # Environment variables
â”‚   â”œâ”€â”€ next.config.js                    # Next.js configuration
â”‚   â”œâ”€â”€ package.json                      # Project dependencies
â”‚   â””â”€â”€ tsconfig.json                     # TypeScript configuration
```

## Usage

1. Click anywhere on the page to initialize audio (required by browser policies)
2. Select a mood using the buttons at the bottom of the screen
3. Wait for the AI to generate music matching your selected mood
4. Use the play/pause button to control playback
5. Enjoy the synchronized visual experience with the generated music

## Development

- `npm run dev` - Start development server
- `npm run build` - Build for production
- `npm run start` - Start production server
- `npm run lint` - Run ESLint

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- [Riffusion](https://www.riffusion.com/) for the AI music generation
- [Three.js](https://threejs.org/) for 3D graphics
- [Next.js](https://nextjs.org/) for the React framework
- [React Three Fiber](https://github.com/pmndrs/react-three-fiber) for React Three.js integration
